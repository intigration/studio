{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xSDP4bMrIL2x"
   },
   "source": [
    "# Multiple Linear Regression\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.   **[Introduction to Multiple Linear Regression](#1.-Introduction-to-Multiple-Linear-Regression)**\n",
    "1.   **[Foundations of Linear Regression](#2.-Foundations-of-Linear-Regression)**\n",
    "1.   **[Model Assumptions](#3.-Model-Assumptions)**\n",
    "1.   **[Variable Selection](#4.-Variable-Selection)**\n",
    "1.   **[Exploratory Data Analysis](#5.-Exploratory-Data-Analysis)**\n",
    "1.   **[Model Construction](#6.-Model-Construction)**\n",
    "1.   **[Model Evaluation](#7.-Model-Evaluation)**\n",
    "1.   **[Model Results](#8.-Model-Results)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"1.-Introduction-to-Multiple-Linear-Regression\"></a>\n",
    "### 1. Introduction to Multiple Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Definitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Linear Regression |** Technique that estimates the linear relationship between one `continuous` dependent variable and `two or more independent` variable. \n",
    "\n",
    "**Dependant variable (y) |** The variable a given model estimates, also referred to as a response or outcome variable\n",
    "\n",
    "**Independent variable (x) |** A variable that explains trends in the dependent variable, also referred to as an explanatory or predictor variable.\n",
    "\n",
    "**Simple Linear Regression Formula |** $y = intercept + slope(x)$\n",
    "\n",
    "**Slope |** The amount that `y` increases or decreases per one-unit increase of `x`\n",
    "\n",
    "**Intercept |** The value of `y`, the dependent variable, when `x`, the independent variable, equals 0\n",
    "\n",
    "**Regression Coefficients |** The estimated betas in a regression model. Represented as $\\hat{\\beta_i}$\n",
    "\n",
    "**Ordinary Least Squares Estimation (OLS) |** Common way to calculate linear regression coefficients $\\hat{(\\beta)}_n$ \n",
    "\n",
    "**Loss Function |** A function that measures the distance between the observed values and the model's estimated values \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Mathematical Multiple Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Linear Regression Equation |** $y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n$\n",
    "\n",
    "**Interaction Term |** A term that represents how the relationship between tow independent variable is associated with changes in the mean of the dependent variable\n",
    "- Equation without interaction: $y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2$\n",
    "- Equation with interaction: $y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_{\\text{interaction}} * (variable1 * variable2)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"2.-Foundations-of-Linear-Regression\"></a>\n",
    "### 2. Foundations of Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Ordinary Least Squares Estimation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary least squares (OLS) is a method used in linear regression analysis to estimate the unknown parameters of the linear regression model. The goal of OLS estimation is to find the values of the regression coefficients that minimize the sum of the squared errors between the predicted values and the actual values of the dependent variable.\n",
    "\n",
    "**Best Fit Line |** The line that fits the data best by minimizing some loss function or error\n",
    "\n",
    "**Predicted values |** The estimated (y) values for each (x) calculated by a model\n",
    "\n",
    "**Residual |** The difference between observed or actual values and the predicted values of the regression line \n",
    "- Residual = Observed - Predicted ---> $\\epsilon_i = y_i - \\hat{y_i}$\n",
    "\n",
    "**Sum of Squared Residuals (SSR) |** The sum of the squared differences between each observed value and its associated predicted value \n",
    "- $SSR = \\sum\\limits_{i=1}^{n}(Observed - Predicted)^2$\n",
    "- $SSR = \\sum\\limits_{i=1}^{n}(y_i - \\hat{y_i})^2$\n",
    "\n",
    "**Ordinary Least Squares (OLS) |** A method that minimizes the sum of the squared residuals to estimate parameters in a linear regression model\n",
    "- Used to calculate: $\\hat{y}=\\hat{\\beta_0} + \\hat{\\beta_1(x)}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"3.-Model-Assumptions\"></a>\n",
    "### 3. Model Assumptions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model assumptions are statements about the data that must be true in order to justify the use of a particular modeling technique\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1 Multiple Linear Regression Assumptions\n",
    "- **Linearity**\n",
    "- **Normality**\n",
    "- **Independent Observations**\n",
    "- **Homoscedasticity**\n",
    "- **No Multicollinearity**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 3.1.1 Linearity\n",
    "\n",
    "**Each predictor variable $(X_i)$ is linearly related to the outcome variable $(Y)$**\n",
    "\n",
    "##### 3.1.2 (Multivariate) Normality\n",
    "\n",
    "**The residuals of errors are normally distributed.**\n",
    "- Can only be checked after the model is built because residuals must be known for calculation\n",
    "- Checked using a quantile-quantile plot (Q-Q plot)\n",
    "    - if points on the plot form a straight diagonal line then can assume normality\n",
    "\n",
    "##### 3.1.3 Independent Observation \n",
    "\n",
    "**Each observation in the dataset is independent**\n",
    "\n",
    "##### 3.1.4 Homoscedasticity\n",
    "\n",
    "**The variation of the residuals (errors) is constant or similar across the model**\n",
    "- Homoscedasticity means having the same scatter\n",
    "\n",
    "##### 3.1.5 No Multicollinearity\n",
    "\n",
    "**No two independent variables ($X_i$ and $X_j$) can be highly correlated with each other.**\n",
    "- Variance Inflation Factors (VIF) quantifies how correlated each independent variable is with all of the other independent variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.2 Assumption Violations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 3.2.1 Linearity\n",
    "**Transform one or both of the variables**, such as taking the logarithm.\n",
    "- For example, if measuring the relationship between years of education and income, take the logarithm of the income variable and check if that helps the linear relationship.\n",
    "\n",
    "##### 3.2.2 Normality\n",
    "**Transform one or both variables.** Most commonly, this would involve taking the logarithm of the outcome variable.\n",
    "- When the outcome variable is right skewed, the normality of the residuals can be affected. Taking the logarithm of the outcome variable can sometimes help with this assumption.\n",
    "- When transforming a variable, reconstruct the model and recheck the normality assumption. If the assumption is still not satisfied, continue troubleshooting the issue.\n",
    "\n",
    "##### 3.2.3 Independent Observation \n",
    "**Take just a subset of the available data.**\n",
    "- If, for example, data is a survey including responses from people in the same household, responses may be correlated. Correct for this by just keeping the data of one person in each household.\n",
    "- Another example data on bike rental over a time period. If data collected every 15 minutes, the number of bikes rented out at 8:00 a.m. might correlate with the number of bikes rented out at 8:15 a.m. Perhaps the number of bikes rented out is independent if the data is taken once every 2 hours, instead of once every 15 minutes.\n",
    "\n",
    "##### 3.2.4 Homoscedasticity\n",
    "**Define a different outcome variable.**\n",
    "- If interested in understanding how a cityâ€™s population correlates with the number of restaurants in a city, it's known that some cities are more populous than others. Therefore possible to redefine the outcome variable as the ratio of population to restaurants instead.\n",
    "\n",
    "**Transform the Y variable.**\n",
    "- As with the above assumptions, sometimes taking the logarithm or transforming the Y variable in another way can potentially fix inconsistencies with the homoscedasticity assumption.\n",
    "\n",
    "##### 3.2.5 No Multicollinearity\n",
    "**Drop Variables**\n",
    "- Drop one or more variables that have high multicollinearity\n",
    "- Strategic variable selection:\n",
    "    - Forward Selection\n",
    "    - Backward elimination \n",
    "- Advanced variable selection:\n",
    "    - Ridge regression\n",
    "    - Lasso regression\n",
    "    - Elastic-net regression\n",
    "    - Principal component analysis(PSA)\n",
    "\n",
    "**Create new Variables**\n",
    "- Use existing data to create new variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"4.-Variable-Selection\"></a>\n",
    "### 4. Variable Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Definitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$R^2$ |** The proportion of variance of the dependent variable, Y, explained by the independent variables, X\n",
    "\n",
    "**Overfitting |** When a model fits the observed rr training data too specifically, and is unable to generate suitable estimates for the general population\n",
    "\n",
    "**Adjusted $R^2$ |** A variation of the $R^2$ regression evaluation metric that penalizes unnecessary explanatory variables\n",
    "\n",
    "**$R^2$ vs. Adjusted $R^2$ |**\n",
    "- Adjusted $R^2$ is used to compare models of varying complexity\n",
    "    - Determine if you should add another variable or not\n",
    "- $R^2$ is more easily interpretable\n",
    "    - Determine how much variation in the dependent variable is explained by the model\n",
    "\n",
    "**When to use adjusted R-squared**\n",
    "- Adjusted R-squared is used to compare between multiple regression models with varying numbers of independent variables. To avoid selecting an overfitted model purely based on inflated R-squared, adjusted R-squared is used to select the optimal model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Selection Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable / Feature selection |** The process of determining which variable or features to include in a given model\n",
    "\n",
    "**Forward Selection |** A stepwise variable selection process that begins with the null model, with 0 independent variables, considers all possible variables to add. It incorporates the independent variable that contributes the most explanatory power to the model. \n",
    "\n",
    "**Backward Elimination |** A stepwise variable selection process that begins with the full model, with all possible independent variables, and removes the independent variable that adds the least explanatory power to the model.  \n",
    "\n",
    "**Extra-sum-of-squares F-test |** Quantifies the difference between the amount of variance that is left unexplained by a reduced model that is explained by the full model\n",
    "\n",
    "**Bias-variance tradeoff |** Balance between two model qualities, bias and variance, to minimize overall error for unobserved data\n",
    "\n",
    "**Regularization |** A set of regression techniques that shrinks regression coefficient estimates toward zero, adding in bias, to reduce variance\n",
    "\n",
    "**Regularized regression |**\n",
    "- Lasso Regression\n",
    "- Ridge Regression\n",
    "- Elastic-net Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"3.-Exploratory-Data-Analysis\"></a>\n",
    "### 5. Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant Python libraries and modules\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load the dataset into a DataFrame and save in a variable\n",
    "\n",
    "data = pd.read_csv(\"example_file.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 10 rows of the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display number of rows, number of columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot to visualize the relationship between the continuous variables in the data\n",
    "sns.pairplot(data);\n",
    "\n",
    "# Important to consider which variables have a linear relationship "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Missing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.1 Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Start with .isna() to get booleans indicating whether each value in the data is missing\n",
    "data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Use .any(axis=1) to get booleans indicating whether there are any missing values along the columns in each row\n",
    "data.isna().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Use .sum() to get the number of rows that contain missing values\n",
    "data.isna().any(axis=1).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2 Drop missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Use .dropna(axis=0) to indicate that you want rows which contain missing values to be dropped\n",
    "# Step 2. To update the DataFrame, reassign it to the result\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure that the data does not contain any rows with missing values now\n",
    "\n",
    "# Step 1. Start with .isna() to get booleans indicating whether each value in the data is missing\n",
    "# Step 2. Use .any(axis=1) to get booleans indicating whether there are any missing values along the columns in each row\n",
    "# Step 3. Use .sum() to get the number of rows that contain missing values\n",
    "data.isna().any(axis=1).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"6.-Model-Construction\"></a>\n",
    "### 6. Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "# Save resulting DataFrame in a separate variable to prepare for regression\n",
    "ols_data = data[[\"Independent variable(Column_n)\", \"Dependant variable(Column_n)\", \"Dependant variable(Column_n)\", \"Dependant variable(Column_n)\" ]] \n",
    "\n",
    "# Display first 10 rows of the new DataFrame\n",
    "ols_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the linear regression formula replacing Y and X with the corresponding column names eg: Sales and Ad_Spend\n",
    "# Save it in a variable\n",
    "ols_formula = \"Dependant variable(Y) ~ Independent variable(X_1) + C(Independent categorical variable(X_2))\" # C(Variable) used for categorical variables\n",
    "\n",
    "# Implement OLS approach for linear regression\n",
    "OLS = ols(formula= ols_formula, data= ols_data)\n",
    "\n",
    "# Fit the model to the data\n",
    "# Save the fitted model in a variable\n",
    "model = OLS.fit()\n",
    "\n",
    "# Save the results summary.\n",
    "model_results = model.summary()\n",
    "\n",
    "# Display the model results.\n",
    "model_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"7.-Model-Evaluation\"></a>\n",
    "### 7. Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Model Assumptions Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.1 Linearity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot for each independent variable and the dependent variable.\n",
    "\n",
    "# Create a 1x2 plot figure.\n",
    "fig, axes = plt.subplots(1, 2, figsize = (8,4))\n",
    "\n",
    "# Create a scatterplot between X_1 and Y.\n",
    "sns.scatterplot(x = ols_data['X_1'], y = ols_data['Y'],ax=axes[0])\n",
    "\n",
    "# Set the title of the first plot.\n",
    "axes[0].set_title(\"X_1 and Y\")\n",
    "\n",
    "# Create a scatterplot between Social Media and Sales.\n",
    "sns.scatterplot(x = ols_data['X_2'], y = ols_data['Y'],ax=axes[1])\n",
    "\n",
    "# Set the title of the second plot.\n",
    "axes[1].set_title(\"X_2 and Y\")\n",
    "\n",
    "# Set the xlabel of the second plot.\n",
    "axes[1].set_xlabel(\"X_2\")\n",
    "\n",
    "# Use matplotlib's tight_layout() function to add space between plots for a cleaner appearance.\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer |** Is there a clear linear relationship in the scatterplot between Y and X variables? If yes then assumption is met."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.2 Independence Check\n",
    "\n",
    "The independent observation assumption states that each observation in the dataset is independent. As each marketing promotion (i.e., row) is independent from one another, the independence assumption is not violated.\n",
    "- Consider whether each row of data is independent from one another is so then the independence assumption is not violated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.3 Normality Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the following plots to check the **normality assumption**:\n",
    "\n",
    "* **Plot 1**: Histogram of the residuals\n",
    "* **Plot 2**: Q-Q plot of the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals.\n",
    "residuals = model.resid\n",
    "\n",
    "# Create a 1x2 plot figure.\n",
    "fig, axes = plt.subplots(1, 2, figsize = (8,4))\n",
    "\n",
    "# Create a histogram with the residuals. \n",
    "sns.histplot(residuals, ax=axes[0])\n",
    "\n",
    "# Set the x label of the residual plot.\n",
    "axes[0].set_xlabel(\"Residual Value\")\n",
    "\n",
    "# Set the title of the residual plot.\n",
    "axes[0].set_title(\"Histogram of Residuals\")\n",
    "\n",
    "# Create a Q-Q plot of the residuals.\n",
    "sm.qqplot(residuals, line='s',ax = axes[1])\n",
    "\n",
    "# Set the title of the Q-Q plot.\n",
    "axes[1].set_title(\"Normal QQ Plot\")\n",
    "\n",
    "# Use matplotlib's tight_layout() function to add space between plots for a cleaner appearance.\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot.\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer |** Based on the visualizations above, is the distribution of the residuals normal?\n",
    "- Is the histogram of the residuals approximately normally distributed?\n",
    "- Are the residuals in the Q-Q plot forming a straight line?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.4 Homoscedasticity(constant variance) Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot with the fitted values from the model and the residuals.\n",
    "fig = sns.scatterplot(x = model.fittedvalues, y = model.resid)\n",
    "\n",
    "# Set the x axis label.\n",
    "fig.set_xlabel(\"Fitted Values\")\n",
    "\n",
    "# Set the y axis label.\n",
    "fig.set_ylabel(\"Residuals\")\n",
    "\n",
    "# Set the title.\n",
    "fig.set_title(\"Fitted Values v. Residuals\")\n",
    "\n",
    "# Add a line at y = 0 to visualize the variance of residuals above and below 0.\n",
    "fig.axhline(0)\n",
    "\n",
    "# Show the plot.\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer:**\n",
    "\n",
    "1. Do the data points have a cloud-like resemblance and do not follow an explicit pattern?\n",
    "    - If yes then normality assumption met"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.5 Multicollinearity Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two common ways to check for multicollinearity are to:**\n",
    "\n",
    "* Create scatterplots to show the relationship between pairs of independent variables\n",
    "* Use the variance inflation factor to detect multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot of the data.\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer:**\n",
    "\n",
    "1. Are the independent variables visibly linearly correlated?\n",
    "    - If no then assumption met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance inflation factor (optional).\n",
    "\n",
    "# Import variance_inflation_factor from statsmodels.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Create a subset of the data with the continuous independent variables. \n",
    "X = ols_data[['X_1','X_2']]\n",
    "\n",
    "# Calculate the variance inflation factor for each variable.\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Create a DataFrame with the VIF results for the column names in X.\n",
    "df_vif = pd.DataFrame(vif, index=X.columns, columns = ['VIF'])\n",
    "\n",
    "# Display the VIF results.\n",
    "df_vif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer:**\n",
    "\n",
    "A VIF value of 1 indicates that there is no correlation between the predictor variables, while a value of greater than 1 indicates that there is some correlation. Generally, a VIF value of 5 or above is considered to indicate a high degree of multicollinearity.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"8.-Model-Results\"></a>\n",
    "### 8. Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model results summary.\n",
    "model_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.1 Drawing conclusions\n",
    "\n",
    "1. Interpret the R-squared value\n",
    "2. Interpret the coefficients:  look at the coefficient estimates and the uncertainty of these estimates\n",
    "    - what are the coefficients\n",
    "    eg.:\n",
    "        * $\\beta_{0} =  218.5261 $\n",
    "        * $\\beta_{TVLow}= -154.2971$\n",
    "        * $\\beta_{TVMedium} = -75.3120 $\n",
    "        * $\\beta_{Radio} =  2.9669$\n",
    "3. Express the relationship that has been modelled as a linear equation:\n",
    "    - eg:\n",
    "        - $\\text{Sales} = \\beta_{0} + \\beta_{1}*X_{1}+ \\beta_{2}*X_{2}+ \\beta_{3}*X_{3}$\n",
    "        - $\\text{Sales} = \\beta_{0} + \\beta_{TVLow}*X_{TVLow}+ \\beta_{TVMedium}*X_{TVMedium}+ \\beta_{Radio}*X_{Radio}$\n",
    "        - $\\text{Sales} = 218.5261 - 154.2971*X_{TVLow} - 75.3120*X_{TVMedium}+ 2.9669 *X_{Radio}$\n",
    "4. What is your interpretation of the coefficient estimates? Are the coefficients statistically significant?\n",
    "5. Beta coefficients allow an estimation of the magnitude and direction (positive or negative) of the effect of each independent variable on the dependent variable. \n",
    "    - The coefficient estimates can be converted to explainable insights, such as the connection between an increase in $X_1$ and $Y$\n",
    "6. What are you interested in exploring further based on the current model?\n",
    "7. Do you think your model could be improved? Why or why not? How?\n",
    "8. What findings would be important to share with stakeholders and how should these be framed for most effective communication. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1BgN3Lv1fx-AxyKSqB_2kM3dJ4mFBctv_",
     "timestamp": 1662734078308
    },
    {
     "file_id": "1ZYfhIvPRxnw7ghB_BsNQAMUorLXpAZs_",
     "timestamp": 1658889786811
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
